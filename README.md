# DavidNet
## The Problem
Most modern vocal music is metrical in nature: The text follows a repeating pattern of syllables in each line. For example, "Amazing Grace" has the metre 8686, known as Common Metre (CM). This metre is shared with the "PokeMon" theme tune from the TV series of the same name. This means that (should you wish) you can sing the words of "Amazing Grace" to the tune of "PokeMon" and vice versa. Hebrew poetry as found in the Bible doesn't follow a metrical pattern (either in the original language or in translation) but is obviously intended to be sung. We know this because many of the Psalms have subheadings specifying a tune, though the original tunes are lost to history. In many modern churches the Psalms simply aren't sung at all: Reading them in unison is the best you will get, apart from Psalms 23 and 100 which have still current metrical translations. Some churches (especially in Scotland) follow the solution pioneered in Calvin's Geneva of translating from the non-metrical Hebrew into metrical English. The downside of this is that compromises have to be made in the accuracy of the translation to fit the metrical pattern. There is another way to approach the problem: Chants. The most famous type of chant is the Gregorian chant, also known as Plainchant, still used in some Roman Catholic churches typically to Latin translations. Gregorian chant repeats many of the words with the same note (the reciting note) with a few other notes at the start, middle and end. We will be concerned with a more recently developed chant known as Anglican chant (because of it's use in many Anglican churches, particularly Cathedrals). With both Gregorian and Anglican chant, the text has to be annotated (a process called 'pointing') to show how the music fits the words. In Anglican chant, once a psalm is pointed it can be fitted to any Anglican chant tune as they all follow a pattern of 4 notes followed by 6 notes. Almost all pointed Anglican psalters (a psalter is a book containing the Psalms) use Coverdale's translation from the original Anglican Book of Common Prayer. This has two disadvantages: First, the language whilst beautiful is very old fashioned (in the same way as the King James version); second, Coverdale translated from Jerome's Latin which in turn was a translation of the Septuagint's Greek which in turn was a translation of the original Hebrew (!). The goal of this project is to train a machine learning model on some pointed Coverdale psalms so that it can then automatically point a more modern (and hopefully more accurate) translation or translations. A stretch goal is to also apply the same model to other parts of the Bible or even secular texts. This will allow more texts to be sung and hopefully aid memorisation of scripture or indeed any text that someone desires to memorise (since it is much easier (and more enjoyable) to memorise lyrics to a tune than spoken prose).

## Preparation of the Data
I will be using the pointed text from [John Speller's webpage](http://spellerweb.net/cmindex/Chant/Psalms.html). These are available as Pdfs. The text is actually from the Episcopal Book of Common Prayer, which has never been under copyright, and John Speller kindly gave me permission to make his pointings available here as well (see [training.txt](training.txt)). To download all of the Pdfs to the current folder, use the following command on a Linux machine (the method will be different on Windows) `wget -e robots=off --no-directories --no-parent -A pdf --recursive --level=1 http://spellerweb.net/cmindex/Chant/{Psalter{A,B,C,D,E,F},Ps119}`. I then used `pdfunite ./* allPdfs.pdf` to combine the pdfs into a single file before manually extracting the psalm texts and putting them in a single .txt file. This file then required some hand editing to fix inconsistencies, mainly things such as whether a pointing symbol was preceded or followed by a space.

## Initial Model
Ths first model is found in Initial One Step Model.ipynb . You will need first to install python 3 along with the numpy, tensorflow, keras and jupyter modules. This is easiest if you use Anaconda or Miniconda. Then navigate to the folder containing the notebook and run "jupyter notebook". The notebook will run in a web browser. Run each cell by clicking it then pressing Cntrl + Enter. You may supply your own test data by editing testCleaned.txt and then running the last cell.

The model tries to do everything in one step: Each line of the test set is fed to a Bidirectional LSTM network which outputs the places where a |, Â· or * should be inserted. It appears that there is not enough training data for the model to learn anything that generalises to unseen material.

If you have a CUDA enabled GPU you can make things a LOT faster by installing Tensorflow with GPU acceleration. On Windows I followed the instructions here: [https://github.com/antoniosehk/keras-tensorflow-windows-installation](https://github.com/antoniosehk/keras-tensorflow-windows-installation).

## GAN Model
To try and improve performance I have also made available a Generative Adversarial Network model. The idea here is that one model (the discriminator) learns to tell the difference between the original pointed psalm and a computer generated one while another model (the generator) tries to fool the discriminator. I haven't used a particularly sophisticated training scheme here so the results are decidedly mixed, but perhaps somebody else can improve on my work! As in the initial model, simply press Cntrl + Enter on each cell in turn to run the programme.